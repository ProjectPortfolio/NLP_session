{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_2",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNjNR953fiM8lcGWfeUrNOV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectPortfolio/NLP_session/blob/main/NLP_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRGZeJmprapV"
      },
      "source": [
        "#import library\n",
        "import nltk\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOWTKX4Yrh75",
        "outputId": "4e210854-4902-49b8-84fb-926adf0359e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "text = \"\"\"Founded in 2002, SpaceX’s mission is to enable humans to become a spacefaring civilization and a multi-planet \n",
        "species by building a self-sustaining city on Mars. In 2008, SpaceX’s Falcon 1 became the first privately developed \n",
        "liquid-fuel launch vehicle to orbit the Earth.\"\"\"\n",
        "# Splits at space \n",
        "text.split() \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Founded',\n",
              " 'in',\n",
              " '2002,',\n",
              " 'SpaceX’s',\n",
              " 'mission',\n",
              " 'is',\n",
              " 'to',\n",
              " 'enable',\n",
              " 'humans',\n",
              " 'to',\n",
              " 'become',\n",
              " 'a',\n",
              " 'spacefaring',\n",
              " 'civilization',\n",
              " 'and',\n",
              " 'a',\n",
              " 'multi-planet',\n",
              " 'species',\n",
              " 'by',\n",
              " 'building',\n",
              " 'a',\n",
              " 'self-sustaining',\n",
              " 'city',\n",
              " 'on',\n",
              " 'Mars.',\n",
              " 'In',\n",
              " '2008,',\n",
              " 'SpaceX’s',\n",
              " 'Falcon',\n",
              " '1',\n",
              " 'became',\n",
              " 'the',\n",
              " 'first',\n",
              " 'privately',\n",
              " 'developed',\n",
              " 'liquid-fuel',\n",
              " 'launch',\n",
              " 'vehicle',\n",
              " 'to',\n",
              " 'orbit',\n",
              " 'the',\n",
              " 'Earth.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Hp68lgCs_fB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWwA0fubS7bi",
        "outputId": "f3f59854-b60e-4ae4-8ac5-241da3d45662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "nltk.download(\"popular\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdilmCbvsKAP"
      },
      "source": [
        "from nltk.tokenize import word_tokenize as wt\n",
        "from nltk.tokenize import sent_tokenize as st\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5byCWYBnspYC",
        "outputId": "ce1d7ce3-faf9-4440-ed2a-11c9e3ee2b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "text=\"I'm Persuing Mtech from TIT CSE.Along with mtech doing training on ML and DL \"\n",
        "print(wt(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', \"'m\", 'Persuing', 'Mtech', 'from', 'TIT', 'CSE.Along', 'with', 'mtech', 'doing', 'training', 'on', 'ML', 'and', 'DL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tksWiihDsuD0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CIp66KlUgGA",
        "outputId": "81fd99ed-caae-4fed-d9ba-51f76021921c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(st(text))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"I'm Persuing Mtech from TIT CSE.Along with mtech doing training on ML and DL\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkcnWssHtjXZ"
      },
      "source": [
        "#white space tokenization on sentence \n",
        "from nltk.tokenize import WhitespaceTokenizer \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjTjd_w-xe_C"
      },
      "source": [
        "tk = WhitespaceTokenizer() \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7RCXvFkxm9V",
        "outputId": "9a00fce3-102f-44df-fa98-e201877036e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "white_token_sentence = tk.tokenize_sents(text)\n",
        "print(white_token_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['I'], [\"'\"], ['m'], [], ['P'], ['e'], ['r'], ['s'], ['u'], ['i'], ['n'], ['g'], [], ['M'], ['t'], ['e'], ['c'], ['h'], [], ['f'], ['r'], ['o'], ['m'], [], ['T'], ['I'], ['T'], [], ['C'], ['S'], ['E'], ['.'], ['A'], ['l'], ['o'], ['n'], ['g'], [], ['w'], ['i'], ['t'], ['h'], [], ['m'], ['t'], ['e'], ['c'], ['h'], [], ['d'], ['o'], ['i'], ['n'], ['g'], [], ['t'], ['r'], ['a'], ['i'], ['n'], ['i'], ['n'], ['g'], [], ['o'], ['n'], [], ['M'], ['L'], [], ['a'], ['n'], ['d'], [], ['D'], ['L'], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKjv_MBfxyws",
        "outputId": "1f03faca-d746-4d45-ea4e-e0e627d24802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "white_token_word = tk.tokenize(text)\n",
        "print(white_token_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"I'm\", 'Persuing', 'Mtech', 'from', 'TIT', 'CSE.Along', 'with', 'mtech', 'doing', 'training', 'on', 'ML', 'and', 'DL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tEAOncox_1r"
      },
      "source": [
        "from nltk import pos_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBVy5yfoyU-I"
      },
      "source": [
        "final_word = pos_tag(white_token_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdELaa7U-Nqm",
        "outputId": "48c39c75-99bb-426e-a40f-da33a578caa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(final_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(\"I'm\", 'NNP'), ('Persuing', 'NNP'), ('Mtech', 'NNP'), ('from', 'IN'), ('TIT', 'NNP'), ('CSE.Along', 'NNP'), ('with', 'IN'), ('mtech', 'JJ'), ('doing', 'VBG'), ('training', 'NN'), ('on', 'IN'), ('ML', 'NNP'), ('and', 'CC'), ('DL', 'NNP')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0sfYrO4-ZIz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}